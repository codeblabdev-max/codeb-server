/**
 * CodeB v7.0 - Project Init/Scan Tool
 *
 * Docker ê¸°ë°˜ ë°°í¬ (v7.0.30+)
 *
 * /we:quick ëª…ë ¹ì–´ì—ì„œ ë‚´ë¶€ì ìœ¼ë¡œ í˜¸ì¶œë¨:
 * - workflow_init (project_init): í”„ë¡œì íŠ¸ ì´ˆê¸°í™”
 * - workflow_scan (project_scan): í”„ë¡œì íŠ¸ ìƒíƒœ ìŠ¤ìº”
 *
 * í”„ë¡œì íŠ¸ ì´ˆê¸°í™” (ì„œë²„ë³„ ë¦¬ì†ŒìŠ¤ ìƒì„±):
 *
 * App Server (158.247.203.55):
 * 1. SSOT ë“±ë¡ (í”„ë¡œì íŠ¸, í¬íŠ¸, DB, Redis ì •ë³´)
 * 2. í¬íŠ¸ í• ë‹¹ (SSOTì™€ ë™ê¸°í™”)
 * 3. ENV íŒŒì¼ ìƒì„± + ë°±ì—…
 * 4. Caddy ë„ë©”ì¸ ì„¤ì •
 *
 * Storage Server (64.176.226.119):
 * 5. PostgreSQL DB/User ìƒì„±
 * 6. Redis DB ë²ˆí˜¸ í• ë‹¹
 *
 * ë¡œì»¬ (ë°˜í™˜ê°’ìœ¼ë¡œ ì œê³µ):
 * 7. GitHub Actions workflow í…œí”Œë¦¿
 * 8. Dockerfile í…œí”Œë¦¿
 */

import { z } from 'zod';
import { randomBytes } from 'crypto';
import type { AuthContext } from '../lib/types.js';
import { withSSH } from '../lib/ssh.js';
import { SERVERS, getSlotPorts } from '../lib/servers.js';

// ============================================================================
// Input Schema
// ============================================================================

export const projectInitInputSchema = z.object({
  projectName: z.string().min(1).max(50),
  type: z.enum(['nextjs', 'remix', 'nodejs', 'python', 'go']).default('nextjs'),
  database: z.boolean().default(true),
  redis: z.boolean().default(true),
  domain: z.string().optional(), // ì‹¤ì œ ë„ë©”ì¸ (ì—†ìœ¼ë©´ {projectName}.codeb.kr)
  // Production Only - Blue-Greenì´ staging ì—­í• ì„ ëŒ€ì²´
});

export const projectScanInputSchema = z.object({
  projectName: z.string().min(1).max(50),
});

// ============================================================================
// Types
// ============================================================================

interface WorkflowInitResult {
  success: boolean;
  projectName: string;
  files: string[];
  ports: {
    blue: number;
    green: number;
  };
  database?: {
    name: string;
    user: string;
    password: string;
    host: string;
    port: number;
    url: string;
  };
  redis?: {
    db: number;
    host: string;
    port: number;
    url: string;
  };
  domain: string;
  registryPath: string;
  githubActionsWorkflow: string;
  dockerfile: string;
  instructions: string[];
  error?: string;
}

interface WorkflowScanResult {
  success: boolean;
  projectName: string;
  registered: boolean;
  hasDockerfile: boolean;
  hasDockerContainer: boolean;
  hasGitHubActions: boolean;
  hasEnv: boolean;
  ports: {
    blue: number;
    green: number;
  };
  issues: string[];
}

// ============================================================================
// Workflow Init
// ============================================================================

async function executeWorkflowInit(
  input: z.infer<typeof projectInitInputSchema>,
  auth: AuthContext
): Promise<WorkflowInitResult> {
  const { projectName, type, database: needsDatabase, redis: needsRedis, domain: inputDomain } = input;

  const files: string[] = [];
  let ports: WorkflowInitResult['ports'] = { blue: 0, green: 0 };
  let dbInfo: WorkflowInitResult['database'];
  let redisInfo: WorkflowInitResult['redis'];
  // ë„ë©”ì¸: ì…ë ¥ê°’ ë˜ëŠ” ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ë„ë©”ì¸
  const domain = inputDomain || `${projectName}.codeb.kr`;

  try {
    // ============================================================
    // Phase 1: App Server (SSOT, í¬íŠ¸, ìŠ¬ë¡¯ ë ˆì§€ìŠ¤íŠ¸ë¦¬)
    // ============================================================
    await withSSH(SERVERS.app.ip, async (appSSH) => {
      // 1. í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„±
      const projectDir = `/opt/codeb/projects/${projectName}`;
      await appSSH.exec(`mkdir -p ${projectDir}`);
      await appSSH.exec(`mkdir -p /opt/codeb/env/${projectName}`);
      await appSSH.exec(`mkdir -p /opt/codeb/env-backup/${projectName}`);

      // 2. í¬íŠ¸ í• ë‹¹ ë° Registry ë“±ë¡
      const registryDir = '/opt/codeb/registry/slots';
      await appSSH.exec(`mkdir -p ${registryDir}`);

      const basePort = await allocatePort(appSSH, projectName);
      ports = getSlotPorts(basePort);

      const registry = {
        projectName,
        teamId: auth.teamId,
        environment: 'production',
        activeSlot: 'blue',
        blue: { name: 'blue', state: 'empty', port: ports.blue },
        green: { name: 'green', state: 'empty', port: ports.green },
        lastUpdated: new Date().toISOString(),
      };

      await appSSH.writeFile(
        `${registryDir}/${projectName}-production.json`,
        JSON.stringify(registry, null, 2)
      );
      files.push(`${registryDir}/${projectName}-production.json`);
    });

    // ============================================================
    // Phase 2: Storage Server (PostgreSQL, Redis)
    // ============================================================
    await withSSH(SERVERS.storage.ip, async (storageSSH) => {
      const dbPassword = generatePassword();
      const dbName = `${projectName}_db`;
      const dbUser = `${projectName}_user`;

      // PostgreSQL DB/User ìƒì„±
      if (needsDatabase) {
        await storageSSH.exec(`sudo -u postgres psql -c "CREATE DATABASE ${dbName};" || true`);
        await storageSSH.exec(`sudo -u postgres psql -c "CREATE USER ${dbUser} WITH PASSWORD '${dbPassword}';" || true`);
        await storageSSH.exec(`sudo -u postgres psql -c "GRANT ALL PRIVILEGES ON DATABASE ${dbName} TO ${dbUser};"`);
        await storageSSH.exec(`sudo -u postgres psql -c "ALTER DATABASE ${dbName} OWNER TO ${dbUser};"`);

        dbInfo = {
          name: dbName,
          user: dbUser,
          password: dbPassword,
          host: SERVERS.storage.domain,
          port: SERVERS.storage.ports.postgresql,
          url: `postgresql://${dbUser}:${dbPassword}@${SERVERS.storage.domain}:${SERVERS.storage.ports.postgresql}/${dbName}?schema=public`,
        };
      }

      // Redis DB ë²ˆí˜¸ í• ë‹¹ (SSOTì—ì„œ ê´€ë¦¬)
      if (needsRedis) {
        // Redis DB ë²ˆí˜¸ëŠ” SSOTì—ì„œ ìë™ í• ë‹¹ (0-15)
        const redisDb = await allocateRedisDb(storageSSH, projectName);
        redisInfo = {
          db: redisDb,
          host: SERVERS.storage.domain,
          port: SERVERS.storage.ports.redis,
          url: `redis://${SERVERS.storage.domain}:${SERVERS.storage.ports.redis}/${redisDb}`,
        };
      }
    });

    // ============================================================
    // Phase 3: App Server (ENV ìƒì„±, SSOT ì—…ë°ì´íŠ¸, Caddy ë„ë©”ì¸)
    // ============================================================
    await withSSH(SERVERS.app.ip, async (appSSH) => {
      // ENV íŒŒì¼ ìƒì„±
      const envContent = generateEnvWithCredentials({
        projectName,
        database: dbInfo,
        redis: redisInfo,
        domain,
      });

      const envPath = `/opt/codeb/env/${projectName}/.env`;
      await appSSH.writeFile(envPath, envContent);
      files.push(envPath);

      // ENV ë°±ì—…
      const backupPath = `/opt/codeb/env-backup/${projectName}/.env.${Date.now()}`;
      await appSSH.exec(`cp ${envPath} ${backupPath}`);

      // SSOT ì—…ë°ì´íŠ¸
      const ssotPath = '/opt/codeb/registry/ssot.json';
      let ssot: any = { version: '7.0', projects: {}, ports: { used: [] }, redis: { used: [] } };

      try {
        const ssotContent = await appSSH.readFile(ssotPath);
        ssot = JSON.parse(ssotContent);
      } catch {
        // íŒŒì¼ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
      }

      ssot.projects[projectName] = {
        teamId: auth.teamId,
        type,
        ports: { blue: ports.blue, green: ports.green },
        database: dbInfo ? { name: dbInfo.name, user: dbInfo.user } : null,
        redis: redisInfo ? { db: redisInfo.db } : null,
        domain,
        createdAt: new Date().toISOString(),
        createdBy: auth.keyId,
      };

      await appSSH.writeFile(ssotPath, JSON.stringify(ssot, null, 2));
      files.push(ssotPath);

      // Caddy ë„ë©”ì¸ ì„¤ì •
      const caddySnippet = `
${domain} {
  reverse_proxy localhost:${ports.blue} localhost:${ports.green} {
    lb_policy first
    fail_duration 10s
  }
  encode gzip
  log {
    output file /var/log/caddy/${projectName}.log
  }
}
`;
      const caddyPath = `/etc/caddy/sites/${projectName}.caddy`;
      await appSSH.exec(`sudo mkdir -p /etc/caddy/sites`);
      await appSSH.exec(`echo '${caddySnippet}' | sudo tee ${caddyPath}`);
      await appSSH.exec(`sudo systemctl reload caddy || true`);
      files.push(caddyPath);

      // PowerDNS A ë ˆì½”ë“œ ì¶”ê°€ (codeb.kr ì„œë¸Œë„ë©”ì¸ì¸ ê²½ìš°ë§Œ)
      if (domain.endsWith('.codeb.kr')) {
        const subdomain = domain.replace('.codeb.kr', '');
        await appSSH.exec(`pdnsutil add-record codeb.kr ${subdomain} A 300 ${SERVERS.app.ip} 2>/dev/null || true`);
        await appSSH.exec(`pdnsutil rectify-zone codeb.kr 2>/dev/null || true`);
      }

      // SSL ì¸ì¦ì„œ ë°œê¸‰ ëŒ€ê¸° (ìµœëŒ€ 30ì´ˆ)
      // Caddyê°€ ìë™ìœ¼ë¡œ Let's Encrypt ì¸ì¦ì„œë¥¼ ë°œê¸‰í•¨
      for (let i = 0; i < 10; i++) {
        await new Promise(resolve => setTimeout(resolve, 3000)); // 3ì´ˆ ëŒ€ê¸°
        const certCheck = await appSSH.exec(
          `curl -sI https://${domain} --connect-timeout 5 2>&1 | head -1 || echo "pending"`
        );
        if (certCheck.stdout.includes('HTTP/') || certCheck.stdout.includes('200')) {
          break; // ì¸ì¦ì„œ ë°œê¸‰ ì™„ë£Œ
        }
      }
    });

    // ============================================================
    // Phase 4: ê²°ê³¼ ë°˜í™˜
    // ============================================================
    const githubActionsWorkflow = generateGitHubActionsWorkflow({ projectName, type });
    const dockerfile = generateDockerfile(type);

    const instructions = [
      `âœ… í”„ë¡œì íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ!`,
      ``,
      `ğŸ“Š í• ë‹¹ëœ ë¦¬ì†ŒìŠ¤:`,
      `   í¬íŠ¸: Blue=${ports.blue}, Green=${ports.green}`,
      dbInfo ? `   DB: ${dbInfo.name} (${dbInfo.user}@${dbInfo.host})` : '',
      redisInfo ? `   Redis: DB ${redisInfo.db}` : '',
      `   ë„ë©”ì¸: ${domain}`,
      ``,
      `ğŸ“ ë¡œì»¬ì— ìƒì„±í•  íŒŒì¼:`,
      `   1. .github/workflows/deploy.yml`,
      `   2. Dockerfile (ì—†ìœ¼ë©´)`,
      ``,
      `ğŸ”‘ GitHub Secrets ì„¤ì •:`,
      `   - CODEB_API_KEY: CodeB API í‚¤`,
      ``,
      `ğŸš€ ë°°í¬:`,
      `   git push origin main  # â†’ ë¹„í™œì„± ìŠ¬ë¡¯ì— ë°°í¬`,
      `   we promote ${projectName}  # â†’ íŠ¸ë˜í”½ ì „í™˜`,
    ].filter(Boolean);

    return {
      success: true,
      projectName,
      files,
      ports,
      database: dbInfo,
      redis: redisInfo,
      domain,
      registryPath: `/opt/codeb/registry/slots/${projectName}-production.json`,
      githubActionsWorkflow,
      dockerfile,
      instructions,
    };
  } catch (error) {
    return {
      success: false,
      projectName,
      files,
      ports,
      domain,
      registryPath: '',
      githubActionsWorkflow: '',
      dockerfile: '',
      instructions: [],
      error: error instanceof Error ? error.message : String(error),
    };
  }
}

// ============================================================================
// Workflow Scan
// ============================================================================

async function executeWorkflowScan(
  input: z.infer<typeof projectScanInputSchema>,
  auth: AuthContext
): Promise<WorkflowScanResult> {
  const { projectName } = input;

  return withSSH(SERVERS.app.ip, async (ssh) => {
    const issues: string[] = [];
    let ports: WorkflowScanResult['ports'] = { blue: 0, green: 0 };

    try {
      const projectDir = `/opt/codeb/projects/${projectName}`;
      const registryDir = '/opt/codeb/registry/slots';

      // Registry í™•ì¸ (Production Only)
      let registered = false;
      try {
        const prodReg = await ssh.readFile(`${registryDir}/${projectName}-production.json`);
        const prodData = JSON.parse(prodReg);
        ports = { blue: prodData.blue.port, green: prodData.green.port };
        registered = true;
      } catch {
        // production ì—†ìŒ
      }

      if (!registered) {
        issues.push('í”„ë¡œì íŠ¸ê°€ Registryì— ë“±ë¡ë˜ì§€ ì•ŠìŒ. /we:quick ì‹¤í–‰ í•„ìš”');
      }

      // Dockerfile í™•ì¸
      let hasDockerfile = false;
      try {
        await ssh.exec(`test -f ${projectDir}/Dockerfile`);
        hasDockerfile = true;
      } catch {
        issues.push('Dockerfileì´ ì—†ìŒ');
      }

      // Docker ì»¨í…Œì´ë„ˆ í™•ì¸
      let hasDockerContainer = false;
      try {
        const result = await ssh.exec(`docker ps -a --format '{{.Names}}' | grep -c "^${projectName}-" || echo "0"`);
        hasDockerContainer = parseInt(result.stdout.trim()) > 0;
      } catch {
        // no docker containers
      }
      if (!hasDockerContainer) {
        issues.push('Docker ì»¨í…Œì´ë„ˆê°€ ì—†ìŒ (ì²« ë°°í¬ í•„ìš”)');
      }

      // GitHub Actions í™•ì¸ (ë¡œì»¬ì—ì„œ í™•ì¸í•´ì•¼ í•¨ - ì—¬ê¸°ì„  skip)
      const hasGitHubActions = false; // ì„œë²„ì—ì„œ í™•ì¸ ë¶ˆê°€

      // ENV í™•ì¸
      let hasEnv = false;
      try {
        await ssh.exec(`test -f ${projectDir}/.env`);
        hasEnv = true;
      } catch {
        issues.push('ENV íŒŒì¼ì´ ì—†ìŒ');
      }

      return {
        success: true,
        projectName,
        registered,
        hasDockerfile,
        hasDockerContainer,
        hasGitHubActions,
        hasEnv,
        ports,
        issues,
      };
    } catch (error) {
      return {
        success: false,
        projectName,
        registered: false,
        hasDockerfile: false,
        hasDockerContainer: false,
        hasGitHubActions: false,
        hasEnv: false,
        ports,
        issues: [error instanceof Error ? error.message : String(error)],
      };
    }
  });
}

// ============================================================================
// Helper Functions
// ============================================================================

function generatePassword(length: number = 32): string {
  return randomBytes(length).toString('base64url').slice(0, length);
}

async function allocateRedisDb(ssh: any, projectName: string): Promise<number> {
  // Redis DB ë²ˆí˜¸ í• ë‹¹ (0-15, 0ì€ ê¸°ë³¸ì´ë¯€ë¡œ 1ë¶€í„° ì‹œì‘)
  const ssotPath = '/opt/codeb/registry/redis-db.json';
  let redisDb: any = { used: {}, nextDb: 1 };

  try {
    const content = await ssh.readFile(ssotPath);
    redisDb = JSON.parse(content);
  } catch {
    // íŒŒì¼ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
  }

  // ì´ë¯¸ í• ë‹¹ëœ í”„ë¡œì íŠ¸ë©´ ê¸°ì¡´ ë²ˆí˜¸ ë°˜í™˜
  if (redisDb.used[projectName]) {
    return redisDb.used[projectName];
  }

  // ìƒˆ DB ë²ˆí˜¸ í• ë‹¹
  const dbNum = redisDb.nextDb;
  if (dbNum > 15) {
    throw new Error('No available Redis DB numbers (max 15)');
  }

  redisDb.used[projectName] = dbNum;
  redisDb.nextDb = dbNum + 1;
  await ssh.writeFile(ssotPath, JSON.stringify(redisDb, null, 2));

  return dbNum;
}

function generateEnvWithCredentials(params: {
  projectName: string;
  database?: WorkflowInitResult['database'];
  redis?: WorkflowInitResult['redis'];
  domain: string;
}): string {
  const { projectName, database, redis, domain } = params;

  let content = `# CodeB v7.0 - Environment Variables
# Project: ${projectName}
# Domain: ${domain}
# Generated: ${new Date().toISOString()}

NODE_ENV=production
PORT=3000

`;

  if (database) {
    content += `# PostgreSQL (Storage Server: ${SERVERS.storage.domain})
DATABASE_URL=${database.url}

`;
  }

  if (redis) {
    content += `# Redis (Storage Server: ${SERVERS.storage.domain})
REDIS_URL=${redis.url}

`;
  }

  content += `# Centrifugo (WebSocket - Streaming Server: ${SERVERS.streaming.domain})
NEXT_PUBLIC_WS_URL=wss://${SERVERS.streaming.domain}/connection/websocket
`;

  return content;
}

async function allocatePort(ssh: any, projectName: string): Promise<number> {
  const ssotPath = '/opt/codeb/registry/ssot.json';
  let ssot: any = { version: '7.0', projects: {}, ports: { allocated: {}, reserved: [] } };

  try {
    const content = await ssh.readFile(ssotPath);
    ssot = JSON.parse(content);
  } catch {
    // íŒŒì¼ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
  }

  // SSOT êµ¬ì¡° ë³´ì¥
  if (!ssot.ports) ssot.ports = { allocated: {}, reserved: [] };
  if (!ssot.ports.allocated) ssot.ports.allocated = {};

  // í¬íŠ¸ ë²”ìœ„ (Production Only): 4100-4998 (ì§ìˆ˜=blue, í™€ìˆ˜=green)
  const baseRange = 4100;
  const maxRange = 4998;

  // allocated ê°ì²´ì—ì„œ ì‚¬ìš© ì¤‘ì¸ í¬íŠ¸ ì¶”ì¶œ
  const usedPorts = new Set(Object.keys(ssot.ports.allocated).map(Number));

  // ì‚¬ìš© ê°€ëŠ¥í•œ ì²« ë²ˆì§¸ ì§ìˆ˜ í¬íŠ¸ ì°¾ê¸° (blueìš©, greenì€ +1)
  for (let port = baseRange; port < maxRange; port += 2) {
    if (!usedPorts.has(port) && !usedPorts.has(port + 1)) {
      // í¬íŠ¸ ì˜ˆì•½ (allocated ê°ì²´ í˜•ì‹)
      ssot.ports.allocated[port] = { project: projectName, slot: 'blue' };
      ssot.ports.allocated[port + 1] = { project: projectName, slot: 'green' };
      await ssh.writeFile(ssotPath, JSON.stringify(ssot, null, 2));
      return port;
    }
  }

  throw new Error('No available ports in production range (4100-4998)');
}

function generateGitHubActionsWorkflow(params: {
  projectName: string;
  type: string;
}): string {
  const { projectName, type } = params;

  // í”„ë¡œì íŠ¸ íƒ€ì…ë³„ ë¹Œë“œ ì„¤ì •
  const buildConfigs: Record<string, { buildCommand: string; nodeVersion: string }> = {
    nextjs: { buildCommand: 'npm run build', nodeVersion: '20' },
    remix: { buildCommand: 'npm run build', nodeVersion: '20' },
    nodejs: { buildCommand: 'npm run build || true', nodeVersion: '20' },
    python: { buildCommand: 'echo "Python project"', nodeVersion: '20' },
    go: { buildCommand: 'go build -o app .', nodeVersion: '20' },
  };

  const config = buildConfigs[type] || buildConfigs.nextjs;

  return `# CodeB v7.0 - Blue-Green Deployment Workflow (Production Only)
# Generated: ${new Date().toISOString()}
#
# Blue-Green ë°°í¬: Staging ì—†ì´ Productionì—ì„œ Blue/Green ìŠ¬ë¡¯ìœ¼ë¡œ ë¬´ì¤‘ë‹¨ ë°°í¬
# - main push â†’ ë¹„í™œì„± ìŠ¬ë¡¯ì— ë°°í¬ (Preview URL ì œê³µ)
# - ìˆ˜ë™ promote â†’ íŠ¸ë˜í”½ ì „í™˜

name: Deploy ${projectName}

on:
  push:
    branches: [main]
  workflow_dispatch:
    inputs:
      action:
        description: 'Action to perform'
        required: true
        default: 'deploy'
        type: choice
        options:
          - deploy
          - promote
          - rollback

env:
  PROJECT_NAME: ${projectName}
  REGISTRY: ghcr.io
  IMAGE_NAME: \${{ github.repository }}

jobs:
  build-and-deploy:
    runs-on: [self-hosted, docker]  # Docker ê¶Œí•œì´ ìˆëŠ” ëŸ¬ë„ˆì—ì„œë§Œ ì‹¤í–‰
    if: github.event_name == 'push' || github.event.inputs.action == 'deploy'
    permissions:
      contents: read
      packages: write

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '${config.nodeVersion}'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Build
        run: ${config.buildCommand}

      - name: Login to GHCR
        uses: docker/login-action@v3
        with:
          registry: \${{ env.REGISTRY }}
          username: \${{ github.actor }}
          password: \${{ secrets.GITHUB_TOKEN }}

      - name: Build and push Docker image
        run: |
          docker build -t \${{ env.REGISTRY }}/\${{ env.IMAGE_NAME }}:\${{ github.sha }} .
          docker push \${{ env.REGISTRY }}/\${{ env.IMAGE_NAME }}:\${{ github.sha }}
          docker tag \${{ env.REGISTRY }}/\${{ env.IMAGE_NAME }}:\${{ github.sha }} \${{ env.REGISTRY }}/\${{ env.IMAGE_NAME }}:latest
          docker push \${{ env.REGISTRY }}/\${{ env.IMAGE_NAME }}:latest

      - name: Deploy to inactive slot (Blue-Green)
        timeout-minutes: 5
        run: |
          RESPONSE=\$(curl -sf --max-time 180 -X POST "https://api.codeb.kr/api/tool" \\
            -H "X-API-Key: \${{ secrets.CODEB_API_KEY }}" \\
            -H "Content-Type: application/json" \\
            -d '{
              "tool": "deploy",
              "params": {
                "projectName": "${projectName}",
                "image": "'\${{ env.REGISTRY }}/\${{ env.IMAGE_NAME }}:\${{ github.sha }}'"
              }
            }')

          echo "Deploy Response: \$RESPONSE"
          PREVIEW_URL=\$(echo "\$RESPONSE" | jq -r '.previewUrl // empty')
          echo "## ğŸš€ Deployed to inactive slot" >> \$GITHUB_STEP_SUMMARY
          echo "Preview URL: \$PREVIEW_URL" >> \$GITHUB_STEP_SUMMARY
          echo "Run 'we promote ${projectName}' to switch traffic" >> \$GITHUB_STEP_SUMMARY

  promote:
    runs-on: [self-hosted, docker]
    if: github.event.inputs.action == 'promote'

    steps:
      - name: Promote (switch traffic)
        run: |
          RESPONSE=\$(curl -sf --max-time 60 -X POST "https://api.codeb.kr/api/tool" \\
            -H "X-API-Key: \${{ secrets.CODEB_API_KEY }}" \\
            -H "Content-Type: application/json" \\
            -d '{"tool": "slot_promote", "params": {"projectName": "${projectName}"}}')
          echo "## ğŸ‰ Traffic switched!" >> \$GITHUB_STEP_SUMMARY

  rollback:
    runs-on: [self-hosted, docker]
    if: github.event.inputs.action == 'rollback'

    steps:
      - name: Rollback to previous version
        run: |
          RESPONSE=\$(curl -sf --max-time 60 -X POST "https://api.codeb.kr/api/tool" \\
            -H "X-API-Key: \${{ secrets.CODEB_API_KEY }}" \\
            -H "Content-Type: application/json" \\
            -d '{"tool": "rollback", "params": {"projectName": "${projectName}"}}')
          echo "## âª Rolled back!" >> \$GITHUB_STEP_SUMMARY
`;
}

function generateDockerfile(type: string): string {
  const templates: Record<string, string> = {
    nextjs: `# CodeB v7.0 - Next.js Dockerfile
FROM node:20-alpine AS base

# Install dependencies only when needed
FROM base AS deps
RUN apk add --no-cache libc6-compat
WORKDIR /app
COPY package*.json ./
RUN npm ci

# Build the application
FROM base AS builder
WORKDIR /app
COPY --from=deps /app/node_modules ./node_modules
COPY . .
RUN npm run build

# Production image
FROM base AS runner
WORKDIR /app
ENV NODE_ENV=production
ENV PORT=3000

RUN addgroup --system --gid 1001 nodejs
RUN adduser --system --uid 1001 nextjs

COPY --from=builder /app/public ./public
COPY --from=builder --chown=nextjs:nodejs /app/.next/standalone ./
COPY --from=builder --chown=nextjs:nodejs /app/.next/static ./.next/static

USER nextjs
EXPOSE 3000
CMD ["node", "server.js"]
`,
    remix: `# CodeB v7.0 - Remix Dockerfile
FROM node:20-alpine AS base

FROM base AS deps
WORKDIR /app
COPY package*.json ./
RUN npm ci

FROM base AS builder
WORKDIR /app
COPY --from=deps /app/node_modules ./node_modules
COPY . .
RUN npm run build

FROM base AS runner
WORKDIR /app
ENV NODE_ENV=production
ENV PORT=3000

COPY --from=deps /app/node_modules ./node_modules
COPY --from=builder /app/build ./build
COPY --from=builder /app/public ./public
COPY package*.json ./

EXPOSE 3000
CMD ["npm", "start"]
`,
    nodejs: `# CodeB v7.0 - Node.js Dockerfile
FROM node:20-alpine

WORKDIR /app
ENV NODE_ENV=production
ENV PORT=3000

COPY package*.json ./
RUN npm ci --only=production

COPY . .

EXPOSE 3000
CMD ["node", "index.js"]
`,
    python: `# CodeB v7.0 - Python Dockerfile
FROM python:3.11-slim

WORKDIR /app
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1
ENV PORT=3000

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

EXPOSE 3000
CMD ["python", "app.py"]
`,
    go: `# CodeB v7.0 - Go Dockerfile
FROM golang:1.21-alpine AS builder

WORKDIR /app
COPY go.mod go.sum ./
RUN go mod download
COPY . .
RUN CGO_ENABLED=0 GOOS=linux go build -o app .

FROM alpine:latest
RUN apk --no-cache add ca-certificates
WORKDIR /app
COPY --from=builder /app/app .

ENV PORT=3000
EXPOSE 3000
CMD ["./app"]
`,
  };

  return templates[type] || templates.nodejs;
}

// ============================================================================
// Export Tools
// ============================================================================

export const projectInitTool = {
  name: 'workflow_init',
  description: 'Initialize project with Registry, Docker, ENV templates',

  async execute(
    params: z.infer<typeof projectInitInputSchema>,
    auth: AuthContext
  ): Promise<WorkflowInitResult> {
    const validated = projectInitInputSchema.parse(params);
    return executeWorkflowInit(validated, auth);
  },
};

export const projectScanTool = {
  name: 'workflow_scan',
  description: 'Scan project for workflow configuration status',

  async execute(
    params: z.infer<typeof projectScanInputSchema>,
    auth: AuthContext
  ): Promise<WorkflowScanResult> {
    const validated = projectScanInputSchema.parse(params);
    return executeWorkflowScan(validated, auth);
  },
};
